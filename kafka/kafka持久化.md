---
Title: kafka高吞吐率是如何做到的？
Keywords:
Desciption:
Date:
LastEditTime:
---

kafka的应用场景

- 实时日志聚合，支持高容量事件流
- 处理大量的数据积压，支持来自离线系统的周期性数据加载
- 处理低延迟分发，分区，分布式，以及实时处理



## 使用linux文件系统和pagecache，放弃内存数据结构

熟知的mysql是通过B+树来持久化到磁盘的，查找数据需要从磁盘读取并构建B+树内存数据结构。而Kafka则是：



- 即使进程维护了内存数据结构，该数据也可能会被复制到操作系统的 pagecache 中，事实上所有内容都被存储了两份。

- 通过自动访问所有空闲内存将可用缓存的容量至少翻倍，并且通过存储紧凑的字节结构而不是独立的对象，有望将缓存容量再翻一番。 这样使得32GB的机器缓存容量可以达到28-30GB,并且不会有额外的 GC 负担
- 保持 内存cache 和 文件系统之间一致性逻辑，不需要做过多的转化。



> 这里不是贬低mysql，只是在某些应用场景下，简单的操作会有更高的效率



